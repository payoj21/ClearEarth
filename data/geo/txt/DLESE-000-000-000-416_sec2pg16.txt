

Page 16 -- The Distribution of Earthquakes 







Seismicity Rates Applied 

Now that you have some experience in determining seismicity rates, and know a little of the basic jargon, the next obvious step is to learn how to apply this skill in such a way that you can begin to draw conclusions about the nature of ongoing seismicity in an area.  But be careful!  As with the task of determining seismicity rates, there are factors here you must also keep in mind, or risk producing ridiculous results and poor conclusions. 

In Activity 5, when you compared the rate of southern California seismicity from one month to that of another, that was a simple application of 
seismicity rates.   It addressed the question, "Does the seismicity rate vary from month to month?"  But what if you wanted to ask the question, "Is the present monthly seismicity rate similar to the rate from 50 years ago?"  Could you simply check the earthquake catalog from 50 years past and compare it to today's?  No.  Any conclusion you made from such a comparison would be questionable, because of a significant difference in your two sets of data.  In this example, that difference would be the size of the network recording the data.  Fifty years ago, the number of seismic recording instruments in southern California was but a small fraction of those that make up today's seismic network, and so only large or favorably located earthquakes would be recorded by enough stations for seismologists to accurately determine their origins. 

There are plenty of other ways to reach poor conclusions when working with data.  It is important to be mindful of the limitations of the data set with which you're working.  Is it too small, or biased in some way?  If you're comparing two different sets, were they collected in essentially identical ways?  In our example above, the two sets were not collected identically, and that could have led to an erroneous conclusion: that the seismicity rate in 1948 was seven times lower than in 1998!  Of course, this comparison was also performed with a data set that was much too small to produce meaningful results, given the generality of the conclusion reached. 
















